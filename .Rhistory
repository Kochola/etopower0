#1.E.4 Creating variable churn rate
churn_kpis_appended_clean <- churn_kpis_appended %>%
group_by(year, week, group_type, Sub_Category) %>%
mutate(churn.rate = (users/sum(users))*100) %>%
filter(visitorType =="Returning Visitor") %>%
select(year, week, Sub_Category, churn.rate, group_type)
rm(churn_kpis_appended)
#####1.F Binding all objects to one long format dataframe/ object for website KPIs and write to hivisasa database
#1.F.1 List the created objects above and name them
KPIs<-list(users_kpis_appended, article_duration_kpis_appended, churn_kpis_appended_clean, pageviews_kpis_appended, session_duration_kpis_appended)
KPIs_names <-list("users","avgTimeOnPage","churn.rate",
"pageviews","avgSessionDuration")
#1.F.2 Replace the KPI metric name with a "variable'
for(i in 1:length(KPIs)){
KPIs[[i]]$KPI <- KPIs_names[[i]]
names(KPIs[[i]])[length(names(KPIs[[i]]))-2] <- "variable"
}
#1.F.3 Bind the objects, and remove unnecessary objects
website_KPIs<-rbindlist(KPIs, use.names = TRUE)
website_KPIs$variable<-round(website_KPIs$variable, 2)
#1.F.4 Create date variable
website_KPIs$week<-as.numeric(website_KPIs$week)
website_KPIs$date.variable <-as.Date(date_from)
rm(KPIs, KPIs_names, users_kpis_appended, article_duration_kpis_appended, churn_kpis_appended_clean, pageviews_kpis_appended, session_duration_kpis_appended)
#1.F.4 Write website.KPIs to hivisasa database
#dbWriteTable(con, "websiteKPIs", website_KPIs, append=TRUE, row.names=FALSE)
#rm(website_KPIs)
###################################################################
#2. Create article KPIs
###################################################################
#### 2.A Pull the articles data for the past month.
#Nb we need the last month, rather than the last week, because some articles may have been
#posted before the last week, but only reviewed and published/rejected in the last week.
#We need to pull the last month, then use this to calculate stats for the last week
#2.A.1 Set up list of dates,list of keep variables, and empty list for days
dates <- as.character(seq(as.Date(date_from)-27, as.Date(date_to), by="days"))
select_variables <- c("_source.id", "_source.status","_source.slug", "_source.post_date",
"_source.publish_date", "_source.writer_id","_source.editor_id",
"_source.location_id","_source.category_id", "_source.kcategory",
"_source.klocation", "_source.title", "_source.body")
#2.A.2 Loop through days, pull the data, and remove unnecessary columns
df1 <- list()
for(i in dates){
print(i)
## Prepare the query
body <- list(query = list(range = list(post_date = list(gte = i, lte = i))))
## Pull the total number of hits between the specified date range
body2 <- Search('articles', body = body)$hits$total
if (body2!=0) {
## Extract the data and convert to a dataframe
body3 <- Search('articles', body = body, asdf = TRUE, size = body2)
df1[[i]] <- body3$hits$hits %>%
select(select_variables)
}
}
#2.A.3 Bind the days, and remove objects
clean_elastic_data <- rbindlist(df1, use.names = TRUE)
rm(body, body2, body3, df1, i, select_variables, dates)
#####2.B Clean up the dataframe
#2.B.1 Convert post date and publish date to a posixct object and extract week and year variables.
clean_elastic_data <- clean_elastic_data %>%
mutate(post.date2= as.POSIXct(`_source.post_date`/1000, origin="1970-01-01", tz = "Africa/Nairobi"),
publish.date2=as.POSIXct(`_source.publish_date`/1000, origin="1970-01-01", tz = "Africa/Nairobi")) %>%
mutate(post.year = lubridate::year(post.date2),
publish.year = lubridate::year(publish.date2))
clean_elastic_data$post.week<-sapply(clean_elastic_data$post.date2, findWeekNo)
clean_elastic_data$publish.week<-sapply(clean_elastic_data$publish.date2, findWeekNo)
#2.B.3 Deal with duplicates. Often a story is submitted multiple times, and the duplicates are rejected. This
#is likely because writers accidently submit several times. We only want one rejected and/or one published
#for each of these stories. However, sometimes an article is submitted several times with revisions due to
#Editor comments. We do want to keep each of these rejections. Hence we will remove duplicates on source title,
#source body, and rejected/accepted status
clean_elastic_data <- clean_elastic_data %>%
distinct(`_source.title`, `_source.body`, `_source.status`, .keep_all = TRUE) %>%
select(-`_source.body`)
#2.B.4 Match editors ID to Editors Name
#Create list of editors IDs
id<-as.list(unique(clean_elastic_data$`_source.editor_id`))
select_variables <- c("_id","_source.name")
#Loop through IDs and match them to name in ES database
df1 <- list()
for(i in id){
if(i!="") {
print(i)
query=paste0("id:",dQuote(i))
## Pull the total number of hits
body2 <- Search('profiles', q=query)$hits$total
## Extract the data and convert to a dataframe
if (body2!=0) {
body3 <- Search('profiles', q=query, asdf = TRUE, size = 1)
df1[[i]] <- body3$hits$hits %>%
select(select_variables)
}
}
}
#Create mapping dataset
mapping <- rbindlist(df1, use.names = TRUE)
rm(body2, body3, df1, id)
#Merge mapping dataset with main data
clean_elastic_data <- merge(clean_elastic_data,mapping,by.x="_source.editor_id", by.y="_id", all.x=T)
clean_elastic_data$`_source.editor_id`<-clean_elastic_data$`_source.name`
clean_elastic_data$`_source.name`<-NULL
rm(mapping)
#Capitalise Editors name
simpleCap <- function(x) {
if (!is.na(x)) {
s <- strsplit(x, " ")[[1]]
paste(toupper(substring(s, 1,1)), substring(s, 2),
sep="", collapse=" ")
}
else {
NA
}
}
clean_elastic_data$`_source.editor_id`<-tolower(clean_elastic_data$`_source.editor_id`)
clean_elastic_data$`_source.editor_id`<-sapply(clean_elastic_data$`_source.editor_id`,simpleCap)
#####2.C Create object for articles submitted
#2.C.1 Create object for the groups (dimensions) required, plus their names
group_bys <- c("`_source.kcategory`", "`_source.klocation`", "`_source.editor_id`")
group_bys_names <- c("category", "location", "editors")
#2.C.2 Loop through and calculate submitted articles overall and by group for the most recent week
#Create empty list
submitted_articles <- list()
#Do for total
submitted_articles[[1]] <- clean_elastic_data %>%
group_by_("post.year", "post.week") %>%
#Get total by week
summarise(variable=n()) %>% ungroup() %>%
#Create naming vars
mutate(group_type = "Total", sub_group = "Total") %>%
#Keep only the most recent week
filter(post.year == recent_year) %>%
filter(post.week == recent_week)
#Do by sub-group
for(i in 1:length(group_bys)){
submitted_articles[[i+1]] <- clean_elastic_data %>%
group_by_("post.year", "post.week",  group_bys[i]) %>%
#Get total by week
summarise(variable=n()) %>% ungroup() %>%
#Create naming vars
mutate(group_type=group_bys_names[i]) %>%
#Keep only the most recent week
filter(post.year == recent_year) %>%
filter(post.week == recent_week)
#Change naming var
names(submitted_articles[[i+1]])[3] <- "sub_group"
}
#Append, add in a column for variable, rename date vars, and remove objects
submitted_articles_appended <- rbindlist(submitted_articles, use.names = TRUE) %>%
mutate(KPI = "Articles Submitted") %>%
rename(year = post.year,
week = post.week)
rm(submitted_articles, group_bys, group_bys_names)
#####2.D Create object for articles published
#2.D.1 Create object for the groups (dimensions) required, plus their names
group_bys <- c("`_source.kcategory`", "`_source.klocation`", "`_source.editor_id`")
group_bys_names <- c("category", "location", "editors")
#2.D.2 Loop through and calculate published articles overall and by group for the most recent week
#Create empty list
published_articles <- list()
#Do for total
published_articles[[1]] <- clean_elastic_data %>%
filter(`_source.status`=="published") %>%
group_by_("publish.year", "publish.week") %>%
#Get total by week
summarise(variable=n()) %>% ungroup() %>%
#Create naming vars
mutate(group_type = "Total", sub_group = "Total") %>%
#Keep only the most recent week
filter(publish.year == recent_year) %>%
filter(publish.week == recent_week)
#Do by sub-group
for(i in 1:length(group_bys)){
published_articles[[i+1]] <- clean_elastic_data %>%
filter(`_source.status`=="published") %>%
group_by_("publish.year", "publish.week",  group_bys[i]) %>%
#Get total by week
summarise(variable=n()) %>% ungroup() %>%
#Create naming vars
mutate(group_type=group_bys_names[i]) %>%
#Keep only the most recent week
filter(publish.year == recent_year) %>%
filter(publish.week == recent_week)
#Change naming var
names(published_articles[[i+1]])[3] <- "sub_group"
}
#Append, add in a column for variable, rename date vars, and remove objects
published_articles_appended <- rbindlist(published_articles, use.names = TRUE) %>%
mutate(KPI = "Articles Published") %>%
rename(year = publish.year,
week = publish.week)
rm(published_articles, group_bys, group_bys_names)
#####2.E Create object for articles rejected
#2.E.1 Create object for the groups (dimensions) required, plus their names
group_bys <- c("`_source.kcategory`", "`_source.klocation`", "`_source.editor_id`")
group_bys_names <- c("category", "location", "editors")
#2.E.2 Loop through and calculate rejected articles overall and by group for the most recent week
#Have to use post date for these
#Create empty list
rejected_articles <- list()
#Do for total
rejected_articles[[1]] <- clean_elastic_data %>%
filter(`_source.status`=="rejected") %>%
group_by_("post.year", "post.week") %>%
#Get total by week
summarise(variable=n()) %>% ungroup() %>%
#Create naming vars
mutate(group_type = "Total", sub_group = "Total") %>%
#Keep only the most recent week
filter(post.year == recent_year) %>%
filter(post.week == recent_week)
#Do by sub-group
for(i in 1:length(group_bys)){
rejected_articles[[i+1]] <- clean_elastic_data %>%
filter(`_source.status`=="rejected") %>%
group_by_("post.year", "post.week",  group_bys[i]) %>%
#Get total by week
summarise(variable=n()) %>% ungroup() %>%
#Create naming vars
mutate(group_type=group_bys_names[i]) %>%
#Keep only the most recent week
filter(post.year == recent_year) %>%
filter(post.week == recent_week)
#Change naming var
names(rejected_articles[[i+1]])[3] <- "sub_group"
}
#Append, add in a column for variable, rename date vars, and remove objects
rejected_articles_appended <- rbindlist(rejected_articles, use.names = TRUE) %>%
mutate(KPI = "Articles Rejected") %>%
rename(year = post.year,
week = post.week)
rm(rejected_articles, group_bys, group_bys_names)
#####2.F Create object for the number of writers who have published articles in a week
#NB, when breaking down by category, the same writer may appear in multiple categories
#2.F.1 Create object for the groups (dimensions) required, plus their names
group_bys <- c("`_source.kcategory`", "`_source.klocation`", "`_source.editor_id`")
group_bys_names <- c("category", "location", "editors")
#2.F.2 Loop through and calculate published articles overall and by group for the most recent week
#Create empty list
writers <- list()
#Do for total
writers[[1]] <- clean_elastic_data %>%
filter(`_source.status`=="published") %>%
group_by_("publish.year", "publish.week") %>%
#Get total by week
summarise(variable= n_distinct(`_source.writer_id`)) %>% ungroup() %>%
#Create naming vars
mutate(group_type = "Total", sub_group = "Total") %>%
#Keep only the most recent week
filter(publish.year == recent_year) %>%
filter(publish.week == recent_week)
#Do by sub-group
for(i in 1:length(group_bys)){
writers[[i+1]] <- clean_elastic_data %>%
filter(`_source.status`=="published") %>%
group_by_("publish.year", "publish.week",  group_bys[i]) %>%
#Get total by week
summarise(variable= n_distinct(`_source.writer_id`)) %>% ungroup() %>%
#Create naming vars
mutate(group_type=group_bys_names[i]) %>%
#Keep only the most recent week
filter(publish.year == recent_year) %>%
filter(publish.week == recent_week)
#Change naming var
names(writers[[i+1]])[3] <- "sub_group"
}
#Append, add in a column for variable, rename date vars, and remove objects
writers_appended <- rbindlist(writers, use.names = TRUE) %>%
mutate(KPI = "Writers Published Articles") %>%
rename(year = publish.year,
week = publish.week)
rm(writers, group_bys, group_bys_names)
#####2.G Create object for the number of articles published per writer
#2.G.1 Create object for the groups (dimensions) required, plus their names
group_bys <- c("`_source.kcategory`", "`_source.klocation`", "`_source.editor_id`")
group_bys_names <- c("category", "location", "editors")
#2.G.2 Loop through and calculate submitted articles overall and by group for the most recent week
#Create empty list
articles_per_writer <- list()
#Do for total
articles_per_writer[[1]] <- clean_elastic_data %>%
filter(`_source.status`=="published") %>%
group_by_("publish.year", "publish.week", "`_source.writer_id`") %>%
#Get total by week
summarise(sum= n()) %>% ungroup() %>%
group_by_("publish.year", "publish.week") %>%
summarise(variable = mean(sum)) %>%
#Create naming vars
mutate(group_type = "Total", sub_group = "Total") %>%
#Keep only the most recent week
filter(publish.year == recent_year) %>%
filter(publish.week == recent_week)
#Need the total number of writers to calculate articles per writer for subgroup
writers <- clean_elastic_data %>%
filter(`_source.status`=="published") %>%
group_by_("publish.year", "publish.week") %>%
#Get total by week
summarise(variable= n_distinct(`_source.writer_id`)) %>% ungroup() %>%
#Create naming vars
mutate(group_type = "Total", sub_group = "Total") %>%
#Keep only the most recent week
filter(publish.year == recent_year) %>%
filter(publish.week == recent_week)
#Do by sub-group
for(i in 1:length(group_bys)){
articles_per_writer[[i+1]] <- clean_elastic_data %>%
filter(`_source.status`=="published") %>%
group_by_("publish.year", "publish.week", "`_source.writer_id`", group_bys[i]) %>%
#Get total by week
summarise(sum= n()) %>% ungroup() %>%
group_by_("publish.year", "publish.week", group_bys[i]) %>%
summarise(variable = sum(sum)/writers$variable) %>%
#Create naming vars
mutate(group_type=group_bys_names[i]) %>%
#Keep only the most recent week
filter(publish.year == recent_year) %>%
filter(publish.week == recent_week)
#Change naming var
names(articles_per_writer[[i+1]])[3] <- "sub_group"
}
#Append, add in a column for variable, rename date vars, and remove objects
articles_per_writer_appended <- rbindlist(articles_per_writer, use.names = TRUE) %>%
mutate(KPI = "Articles Published Per Writer") %>%
rename(year = publish.year,
week = publish.week)
rm(articles_per_writer, group_bys, group_bys_names, writers)
#####2.H Create object for the number of page views per article published in the week
#2.H.1 Extract data from google analytics on pageviews per article
#Choose dimensions for this KPI
dimensions_pageviews <- c('Total')
#Loop through dimensions, capturing KPI
pageviews_per_article <- list()
for(i in seq_along(dimensions_pageviews)){
print(paste("Mining Dimension:", dimensions_pageviews[i]))
pageviews_per_article[[i]] <- google_analytics(my_id,
date_range=c(date_from, date_to),
metrics <- 'pageviews',
dimensions = setdiff(c("year", "week", 'dimension5', dimensions_pageviews[i]), "Total"),
anti_sample = TRUE)
pageviews_per_article[[i]]$group_type <- dimensions_pageviews[i]
names(pageviews_per_article[[i]])[names(pageviews_per_article[[i]])==dimensions_pageviews[i]] <- "Sub_Category"
}
#Append dimensions together and merge with articles dataset
pageviews_per_article_appended <- bind_rows(pageviews_per_article)
rm(pageviews_per_article)
clean_elastic_data <- merge(clean_elastic_data, pageviews_per_article_appended,by.y="dimension5", by.x="_source.id", all=T)
rm(pageviews_per_article_appended)
#2.H.2 Calculate average number of pageviews per article published in the week in total.
pageviews_per_article <- list()
pageviews_per_article[[1]] <- clean_elastic_data %>%
filter(`_source.status`=="published") %>%
group_by_("publish.year", "publish.week") %>%
summarise(variable= mean(pageviews, na.rm=T)) %>%
#Keep only the most recent week
filter(publish.year == recent_year) %>%
filter(publish.week == recent_week)
pageviews_per_article[[1]]$group_type <- "Total"
pageviews_per_article[[1]]$sub_group <- "Total"
#2.H.3 Average number of pageviews per article by category and location.
group_bys <- c("`_source.kcategory`", "`_source.klocation`", "`_source.editor_id`")
group_bys_names <- c("category", "location", "editors")
#Do by sub-group
for(i in 1:length(group_bys)){
pageviews_per_article[[i+1]] <- clean_elastic_data %>%
filter(`_source.status`=="published") %>%
group_by_("publish.year", "publish.week",  group_bys[i]) %>%
#Get total by week
summarise(variable= mean(pageviews)) %>% ungroup %>%
#Create naming vars
mutate(group_type=group_bys_names[i]) %>%
#Keep only the most recent week
filter(publish.year == recent_year) %>%
filter(publish.week == recent_week)
#Change naming var
names(pageviews_per_article[[i+1]])[3] <- "sub_group"
}
#2.H.4 Append the two data objects and clean
#Append and remove objects
pageviews_per_article_KPI <- rbindlist(pageviews_per_article, use.names = TRUE) %>%
mutate(KPI = "Average Pageviews Per Article Published")%>%
rename(year = publish.year,
week = publish.week)
rm(pageviews_per_article, dimensions_pageviews)
#####2.I Append together objects into a single articles KPI object
articles_kpi_list <- list(submitted_articles_appended, published_articles_appended,
rejected_articles_appended, writers_appended,
articles_per_writer_appended, pageviews_per_article_KPI)
articles_KPIs <- rbindlist(articles_kpi_list, use.names = TRUE, fill=T)
articles_KPIs$variable<-round(articles_KPIs$variable, 2)
#2.I Create date variable
articles_KPIs$week<-as.numeric(articles_KPIs$week)
articles_KPIs$date.variable <-as.Date(date_from)
rm(submitted_articles_appended, published_articles_appended,
rejected_articles_appended, writers_appended,
articles_per_writer_appended, pageviews_per_article_KPI,
articles_kpi_list)
#####2.J Write the final articles object to the DB
#dbWriteTable(con, "articlesKPIs", articles_KPIs, append=TRUE, row.names=FALSE)
#rm(articles_KPIs)
###################################################################
#3. Create financials KPIs
###################################################################
###3.1 Get and clean Cost and Revenue data from Google Sheet
#Authenticate into Google Sheets and retrieve the Finanacial KPIs GoogleSheet
gs_auth(token = "/Users/alessandronava/Desktop/ttt.rds")
test<-gs_key("1do3QhJ5lSy8ExSozJFT0wh6DIQ1fj72R-olmcm2c7HE")
revenue<-gs_read(test, ws="Revenue")
cost<-gs_read(test, ws="Costs")
rm(test)
#Remove variables starting with * as they don't contain any data (those variables are only titles)
cost<-cost[!grepl("*", cost$`Week #`, fixed = TRUE),]
revenue<-revenue[!grepl("*", revenue$`Week #`, fixed = TRUE),]
#From wide to long
cost<-melt(cost, id.vars="Week #")
revenue<-melt(revenue, id.vars="Week #")
#Calculate Weeks
cost$week<-substr(cost$variable, 1, 2)
revenue$week<-substr(revenue$variable, 1, 2)
#Calculate years
cost$year<-2016
cost$year2<-if_else(cost$week<lag(cost$week), 1, 0)
cost$year2[!is.na(cost$year2)] <- cumsum(na.omit(cost$year2))
cost$year <- rowSums(cost[,c("year", "year2")], na.rm=TRUE)
cost$year2<-NULL
revenue$year<-2016
revenue$year2<-if_else(revenue$week<lag(revenue$week), 1, 0)
revenue$year2[!is.na(revenue$year2)] <- cumsum(na.omit(revenue$year2))
revenue$year <- rowSums(revenue[,c("year", "year2")], na.rm=TRUE)
revenue$year2<-NULL
#Rename variables
revenue$variable<-NULL
cost$variable<-NULL
revenue <- plyr::rename(revenue, c(`Week #`="group_type"))
cost <- plyr::rename(cost, c(`Week #`="group_type"))
revenue$Sub_Category<-"Total"
cost$Sub_Category<-"Total"
revenue <- plyr::rename(revenue, c(value="variable"))
cost <- plyr::rename(cost, c(value="variable"))
#Filter to keep only the week we are interested in and calculate start of the week
cost$week<-as.numeric(cost$week)
revenue$week<-as.numeric(revenue$week)
cost_KPIs<-cost[cost$year==recent_year & cost$week==recent_week, ]
revenue_KPIs<-revenue[revenue$year==recent_year & revenue$week==recent_week, ]
cost_KPIs$week<-as.numeric(cost_KPIs$week)
cost_KPIs$date.variable <-as.Date(date_from)
revenue_KPIs$week<-as.numeric(revenue_KPIs$week)
revenue_KPIs$date.variable <-as.Date(date_from)
rm(revenue, cost)
####3.2 Create Revenues_KPI
#Calculate total revenue
revenue_total <- revenue_KPIs %>%
group_by_("year", "week", "date.variable") %>%
#Get total by week
summarise(variable=sum(variable)) %>% ungroup() %>%
#Create naming vars
mutate(group_type = "Total", Sub_Category= "Total")
revenue_KPIs<-rbindlist(list(revenue_KPIs, revenue_total), fill = TRUE)
rm(revenue_total)
#Calculate revenue as % share of pageviews by location and by category
revenue_category<-website_KPIs %>%
filter(KPI=="pageviews" & (group_type=="dimension3" | group_type=="dimension4") & week==recent_week) %>%
group_by(group_type) %>%
mutate(percentage=variable/sum(variable)) %>%
mutate(variable=percentage*revenue_KPIs[group_type=="Total" & week==recent_week]$variable) %>%
select (-c(KPI, percentage)) %>%
ungroup()
revenue_KPIs<-rbindlist(list(revenue_KPIs, revenue_category), fill = TRUE)
rm(revenue_category)
revenue_KPIs$variable<-round(revenue_KPIs$variable, 2)
####3.3 Create Cost_KPI
#Calculate total cost
cost_total <- cost_KPIs %>%
group_by_("year", "week", "date.variable") %>%
#Get total by week
summarise(variable=sum(variable)) %>%
ungroup() %>%
#Create naming vars
mutate(group_type = "Total", Sub_Category= "Total")
cost_KPIs<-rbindlist(list(cost_KPIs, cost_total), fill = TRUE)
rm(cost_total)
#Calculate cost per article
cost_article <- cost_KPIs %>%
summarise(group_type = "Cost per Article",
year= recent_year,
week= recent_week,
variable= (cost_KPIs[group_type=="Total" & week==recent_week]$variable/articles_KPIs[KPI=="Articles Published" & group_type=="Total" & week==recent_week]$variable),
Sub_Category="Cost per Article",
date.variable=cost_KPIs[group_type=="Total" & week==recent_week]$date.variable)
cost_KPIs<-rbindlist(list(cost_KPIs, cost_article), fill = TRUE)
rm(cost_article)
#Calculate cost by articles location and by category
cost_category<-articles_KPIs %>%
filter(KPI=="Articles Published" & (group_type=="location" | group_type=="category") & week==recent_week) %>%
mutate(variable=variable*cost_KPIs[group_type=="Cost per Article" & week==recent_week]$variable) %>%
select (-c(KPI))
cost_category <- plyr::rename(cost_category, c(sub_group="Sub_Category"))
cost_KPIs<-rbindlist(list(cost_KPIs, cost_category), fill = TRUE)
rm(cost_category)
####3.4 Create Payout per article
#Get pageviews per article for the last 27 days
dimensions_pageviews <- c('Total')
pageviews_per_article <- list()
for(i in seq_along(dimensions_pageviews)){
print(paste("Mining Dimension:", dimensions_pageviews[i]))
pageviews_per_article[[i]] <- google_analytics(my_id,
date_range=c(date_from-27, date_to),
metrics <- 'pageviews',
dimensions = setdiff(c("year", "week", 'dimension5', dimensions_pageviews[i]), "Total"),
anti_sample = TRUE)
pageviews_per_article[[i]]$group_type <- dimensions_pageviews[i]
names(pageviews_per_article[[i]])[names(pageviews_per_article[[i]])==dimensions_pageviews[i]] <- "Sub_Category"
}
